from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
import os
from google import genai  # Import the Gemini client

# Define the request model for the API to accept the query
class AskRequest(BaseModel):
    query: str

router = APIRouter()

EXTRACTED_TEXT_PATH = "extracted_text.txt"
MAX_CONTEXT_CHARS = 200_000  # Trim huge files to avoid token limits

# The Gemini API key directly here
GEMINI_API_KEY = "AIzaSyBDjYvJUqnUeLWoa7KPyZAvHANwqGZqdgo"  # Replace with your actual API key

@router.post("/ask-question/")
async def ask_question(payload: AskRequest):
    query = (payload.query or "").strip()
    if not query:
        raise HTTPException(status_code=422, detail="Query cannot be empty.")

    # Ensure context exists (extracted text file should be uploaded first)
    if not os.path.exists(EXTRACTED_TEXT_PATH):
        raise HTTPException(status_code=404, detail="Extracted text file not found. Please upload a file first.")

    try:
        # Read the extracted text from the file
        with open(EXTRACTED_TEXT_PATH, "r", encoding="utf-8", errors="ignore") as f:
            context = f.read()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to read context: {e}")

    if not context.strip():
        raise HTTPException(status_code=400, detail="Extracted text is empty. Please re-upload a valid document.")

    # Trim the context if it's too long (Gemini models have token limits)
    if len(context) > MAX_CONTEXT_CHARS:
        context = context[:MAX_CONTEXT_CHARS]

    try:
        # Initialize the Gemini client with the API key directly
        client = genai.Client(api_key=GEMINI_API_KEY)

        # Concise prompt for the model to strictly answer the query based on the context
        prompt = (
            f"Answer the question directly using the provided context. "
            f"Question: {query}\n\n"
            f"Context:\n{context}"
        )

        # Call the Gemini model to generate content
        result = client.models.generate_content(
            model="gemini-2.5-flash",  # Specify the model to use
            contents=prompt
        )

        # Extract the answer from the result
        answer = getattr(result, "text", None) or "Sorry, I couldn't generate a response."

        # Return the answer generated by the model
        return {"answer": answer}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Gemini error: {e}")
